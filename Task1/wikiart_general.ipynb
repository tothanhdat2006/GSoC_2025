{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bd01ff",
   "metadata": {
    "papermill": {
     "duration": 0.003979,
     "end_time": "2025-03-29T10:04:26.367624",
     "exception": false,
     "start_time": "2025-03-29T10:04:26.363645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da68978",
   "metadata": {
    "papermill": {
     "duration": 0.003131,
     "end_time": "2025-03-29T10:04:26.374367",
     "exception": false,
     "start_time": "2025-03-29T10:04:26.371236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CNN - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a73c3e",
   "metadata": {
    "papermill": {
     "duration": 0.003056,
     "end_time": "2025-03-29T10:04:26.393407",
     "exception": false,
     "start_time": "2025-03-29T10:04:26.390351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036af15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:26.400978Z",
     "iopub.status.busy": "2025-03-29T10:04:26.400769Z",
     "iopub.status.idle": "2025-03-29T10:04:36.439095Z",
     "shell.execute_reply": "2025-03-29T10:04:36.438142Z"
    },
    "papermill": {
     "duration": 10.044089,
     "end_time": "2025-03-29T10:04:36.440823",
     "exception": false,
     "start_time": "2025-03-29T10:04:26.396734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "corrupted_images = [\n",
    "    'Baroque/rembrandt_woman-standing-with-raised-hands.jpg',\n",
    "    'Post_Impressionism/vincent-van-gogh_l-arlesienne-portrait-of-madame-ginoux-1890.jpg'\n",
    "]\n",
    "\n",
    "class TRAIN_GeneralArtGANDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.artist_classes_csv = pd.read_csv(data_path / f'artist_class.txt', sep=\" \", names=['label', 'name'])\n",
    "        self.genre_classes_csv = pd.read_csv(data_path / f'genre_class.txt', sep=\" \", names=['label', 'name'])\n",
    "        self.style_classes_csv = pd.read_csv(data_path / f'style_class.txt', sep=\" \", names=['label', 'name'])\n",
    "\n",
    "        # --------------------------- Cleaning data\n",
    "        \n",
    "        artist_csv = pd.read_csv(data_path / f'artist_train.csv', names=['filename', 'label'])\n",
    "        genre_csv = pd.read_csv(data_path / f'genre_train.csv', names=['filename', 'label'])\n",
    "        style_csv = pd.read_csv(data_path / f'style_train.csv', names=['filename', 'label'])\n",
    "        artist_csv = artist_csv.query(\"filename not in @corrupted_images\")\n",
    "        genre_csv = genre_csv.query(\"filename not in @corrupted_images\")\n",
    "        style_csv = style_csv.query(\"filename not in @corrupted_images\")\n",
    "        \n",
    "        import re\n",
    "        import unicodedata\n",
    "        def process_filename(f):\n",
    "            dirname, filename = f.split('/', 1)\n",
    "            normalized = unicodedata.normalize('NFKD', filename)\n",
    "            ascii_filename = ''\n",
    "            for char in normalized:\n",
    "                if ord(char) < 128 and ord(char) != 39:\n",
    "                    ascii_filename += char\n",
    "                else:\n",
    "                    replacements = {\n",
    "                        'ä': 'a', 'ö': 'o', 'ü': 'u', 'ß': 'ss',\n",
    "                        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "                        'à': 'a', 'è': 'e', 'ì': 'i', 'ò': 'o', 'ù': 'u',\n",
    "                        'â': 'a', 'ê': 'e', 'î': 'i', 'ô': 'o', 'û': 'u',\n",
    "                    }\n",
    "                    ascii_filename += replacements.get(char, '_') # Replace with _ \n",
    "        \n",
    "            ascii_filename = re.sub(r'[^a-zA-Z0-9_\\-\\.]', '_', ascii_filename)\n",
    "            return dirname + \"/\" + ascii_filename\n",
    "        \n",
    "        artist_csv.loc[:, \"filename\"] = artist_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        genre_csv.loc[:, \"filename\"] = genre_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        style_csv.loc[:, \"filename\"] = style_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        artist_genre = artist_csv.merge(genre_csv, how='outer', on='filename') # OUTER JOIN\n",
    "        self.data_csv = artist_genre.merge(style_csv, how='outer', on='filename') # OUTER JOIN\n",
    "        self.data_csv = self.data_csv.rename(columns={'label_x': 'artist', 'label_y': 'genre', 'label': 'style'})\n",
    "        # Add dummy class for genre and style\n",
    "        self.data_csv['artist'] = self.data_csv['artist'].fillna(len(self.artist_classes_csv))\n",
    "        self.data_csv['genre'] = self.data_csv['genre'].fillna(len(self.genre_classes_csv))\n",
    "        self.data_csv['style'] = self.data_csv['style'].fillna(len(self.style_classes_csv))\n",
    "        \n",
    "        self.imgs_path = self.data_csv[\"filename\"].tolist()\n",
    "        labels_artist = self.data_csv[\"artist\"].tolist()\n",
    "        labels_genre = self.data_csv[\"genre\"].tolist()\n",
    "        labels_style = self.data_csv[\"style\"].tolist()\n",
    "        self.labels = [(labels_artist[idx], labels_genre[idx], labels_style[idx]) for idx in range(len(self.imgs_path))]\n",
    "\n",
    "        # --------------------------- Custom transforms for train dataset\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop((224,224)),\n",
    "            transforms.RandomHorizontalFlip(0.3),\n",
    "            transforms.RandomVerticalFlip(0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return (len(self.artist_classes_csv)+1, \n",
    "                len(self.genre_classes_csv)+1, \n",
    "                len(self.style_classes_csv)+1)\n",
    "\n",
    "    def get_label_artist(self, label):\n",
    "        return self.artist_classes_csv['name'][label]\n",
    "        \n",
    "    def get_label_genre(self, label):\n",
    "        if label == len(self.genre_classes_csv):\n",
    "            return \"unknown genre\"\n",
    "        return self.genre_classes_csv['name'][label]\n",
    "        \n",
    "    def get_label_style(self, label):\n",
    "        if label == len(self.style_classes_csv):\n",
    "            return \"unknown style\"\n",
    "        return self.style_classes_csv['name'][label]\n",
    "    \n",
    "    def transform(self, img):\n",
    "        img = self.train_transforms(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data_path / self.imgs_path[idx])\n",
    "        label = self.labels[idx] # (artist, genre, style)\n",
    "        img = self.transform(img)\n",
    "        return {\n",
    "            'images': img,\n",
    "            'labels': torch.tensor(label) # (3)\n",
    "        }\n",
    "\n",
    "\n",
    "class VAL_GeneralArtGANDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.artist_classes_csv = pd.read_csv(data_path / f'artist_class.txt', sep=\" \", names=['label', 'name'])\n",
    "        self.genre_classes_csv = pd.read_csv(data_path / f'genre_class.txt', sep=\" \", names=['label', 'name'])\n",
    "        self.style_classes_csv = pd.read_csv(data_path / f'style_class.txt', sep=\" \", names=['label', 'name'])\n",
    "\n",
    "        # --------------------------- Cleaning data\n",
    "        \n",
    "        artist_csv = pd.read_csv(data_path / f'artist_val.csv', names=['filename', 'label'])\n",
    "        genre_csv = pd.read_csv(data_path / f'genre_val.csv', names=['filename', 'label'])\n",
    "        style_csv = pd.read_csv(data_path / f'style_val.csv', names=['filename', 'label'])\n",
    "        artist_csv = artist_csv.query(\"filename not in @corrupted_images\")\n",
    "        genre_csv = genre_csv.query(\"filename not in @corrupted_images\")\n",
    "        style_csv = style_csv.query(\"filename not in @corrupted_images\")\n",
    "        \n",
    "        import re\n",
    "        import unicodedata\n",
    "        def process_filename(f):\n",
    "            dirname, filename = f.split('/', 1)\n",
    "            normalized = unicodedata.normalize('NFKD', filename)\n",
    "            ascii_filename = ''\n",
    "            for char in normalized:\n",
    "                if ord(char) < 128 and ord(char) != 39:\n",
    "                    ascii_filename += char\n",
    "                else:\n",
    "                    replacements = {\n",
    "                        'ä': 'a', 'ö': 'o', 'ü': 'u', 'ß': 'ss',\n",
    "                        'á': 'a', 'é': 'e', 'í': 'i', 'ó': 'o', 'ú': 'u',\n",
    "                        'à': 'a', 'è': 'e', 'ì': 'i', 'ò': 'o', 'ù': 'u',\n",
    "                        'â': 'a', 'ê': 'e', 'î': 'i', 'ô': 'o', 'û': 'u',\n",
    "                    }\n",
    "                    ascii_filename += replacements.get(char, '_') # Replace with _ \n",
    "        \n",
    "            ascii_filename = re.sub(r'[^a-zA-Z0-9_\\-\\.]', '_', ascii_filename)\n",
    "            return dirname + \"/\" + ascii_filename\n",
    "        \n",
    "        artist_csv.loc[:, \"filename\"] = artist_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        genre_csv.loc[:, \"filename\"] = genre_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        style_csv.loc[:, \"filename\"] = style_csv[\"filename\"].map(process_filename) # Pandas 3.0\n",
    "        artist_genre = artist_csv.merge(genre_csv, how='outer', on='filename') # OUTER JOIN\n",
    "        self.data_csv = artist_genre.merge(style_csv, how='outer', on='filename') # OUTER JOIN\n",
    "        self.data_csv = self.data_csv.rename(columns={'label_x': 'artist', 'label_y': 'genre', 'label': 'style'})\n",
    "        # Add dummy class for genre and style\n",
    "        self.data_csv['artist'] = self.data_csv['artist'].fillna(len(self.artist_classes_csv))\n",
    "        self.data_csv['genre'] = self.data_csv['genre'].fillna(len(self.genre_classes_csv))\n",
    "        self.data_csv['style'] = self.data_csv['style'].fillna(len(self.style_classes_csv))\n",
    "        \n",
    "        self.imgs_path = self.data_csv[\"filename\"].tolist()\n",
    "        labels_artist = self.data_csv[\"artist\"].tolist()\n",
    "        labels_genre = self.data_csv[\"genre\"].tolist()\n",
    "        labels_style = self.data_csv[\"style\"].tolist()\n",
    "        self.labels = [(labels_artist[idx], labels_genre[idx], labels_style[idx]) for idx in range(len(self.imgs_path))]\n",
    "\n",
    "        # --------------------------- Custom transforms for train dataset\n",
    "        self.val_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return (len(self.artist_classes_csv)+1, \n",
    "                len(self.genre_classes_csv)+1, \n",
    "                len(self.style_classes_csv)+1)\n",
    "\n",
    "    def get_label_artist(self, label):\n",
    "        if label == len(self.artist_classes_csv):\n",
    "            return \"unknown artist\"\n",
    "        return self.artist_classes_csv['name'][label]\n",
    "        \n",
    "    def get_label_genre(self, label):\n",
    "        if label == len(self.genre_classes_csv):\n",
    "            return \"unknown genre\"\n",
    "        return self.genre_classes_csv['name'][label]\n",
    "        \n",
    "    def get_label_style(self, label):\n",
    "        if label == len(self.style_classes_csv):\n",
    "            return \"unknown style\"\n",
    "        return self.style_classes_csv['name'][label]\n",
    "    \n",
    "    def transform(self, img):\n",
    "        img = self.val_transforms(img)\n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data_path / self.imgs_path[idx])\n",
    "        label = self.labels[idx] # (artist, genre, style)\n",
    "        img = self.transform(img)\n",
    "        return {\n",
    "            'images': img,\n",
    "            'labels': torch.tensor(label) # (3)\n",
    "        }\n",
    "\n",
    "\n",
    "path = Path('/kaggle/input/wikiart') \n",
    "train_dataset = TRAIN_GeneralArtGANDataset(data_path=path)\n",
    "test_dataset = VAL_GeneralArtGANDataset(data_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7374ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:36.448808Z",
     "iopub.status.busy": "2025-03-29T10:04:36.448571Z",
     "iopub.status.idle": "2025-03-29T10:04:38.404602Z",
     "shell.execute_reply": "2025-03-29T10:04:38.403917Z"
    },
    "papermill": {
     "duration": 1.961622,
     "end_time": "2025-03-29T10:04:38.406155",
     "exception": false,
     "start_time": "2025-03-29T10:04:36.444533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "generator1 = torch.Generator().manual_seed(86)\n",
    "\n",
    "train_dataset = TRAIN_GeneralArtGANDataset(data_path=path)\n",
    "val_dataset = VAL_GeneralArtGANDataset(data_path=path)\n",
    "    \n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers, \n",
    "    shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afad169c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:38.414150Z",
     "iopub.status.busy": "2025-03-29T10:04:38.413901Z",
     "iopub.status.idle": "2025-03-29T10:04:39.618218Z",
     "shell.execute_reply": "2025-03-29T10:04:39.617302Z"
    },
    "papermill": {
     "duration": 1.210069,
     "end_time": "2025-03-29T10:04:39.619884",
     "exception": false,
     "start_time": "2025-03-29T10:04:38.409815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 11 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 211MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "class CNN_RNN(nn.Module):\n",
    "    def __init__(self, num_artist_classes, num_genre_classes, num_style_classes, lstm_hidden_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        self.num_artist_classes = num_artist_classes\n",
    "        self.num_genre_classes = num_genre_classes\n",
    "        self.num_style_classes = num_style_classes\n",
    "\n",
    "        resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.cnn = nn.Sequential(*(list(resnet.children())[:-2]))\n",
    "        self.pool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=2048, \n",
    "                            hidden_size=lstm_hidden_dim, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.artist_fc = nn.Linear(lstm_hidden_dim, num_artist_classes)\n",
    "        self.genre_fc = nn.Linear(lstm_hidden_dim, num_genre_classes)\n",
    "        self.style_fc = nn.Linear(lstm_hidden_dim, num_style_classes)\n",
    "\n",
    "    def forward(self, images, labels=None):\n",
    "        batch_size = images.shape[0]\n",
    "\n",
    "        # CNN\n",
    "        cnn_features = self.pool(self.cnn(images)) # (B, 2048, 7, 7)\n",
    "        cnn_features = cnn_features.reshape(batch_size, 49, 2048) # (B, 49, 2048)\n",
    "\n",
    "        # RNN\n",
    "        _, (h_n, _) = self.lstm(cnn_features) # h_n (seq_len, )\n",
    "        final_feature = h_n[-1]\n",
    "\n",
    "        out_artist = self.artist_fc(final_feature)\n",
    "        out_genre = self.genre_fc(final_feature)\n",
    "        out_style = self.style_fc(final_feature)\n",
    "        return out_artist, out_genre, out_style\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_artist_classes, num_genre_classes, num_style_classes = train_dataset.get_num_classes()\n",
    "print(num_artist_classes, num_genre_classes, num_style_classes)\n",
    "model = CNN_RNN(num_artist_classes, num_genre_classes, num_style_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023d1e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:39.628822Z",
     "iopub.status.busy": "2025-03-29T10:04:39.628569Z",
     "iopub.status.idle": "2025-03-29T10:04:39.646585Z",
     "shell.execute_reply": "2025-03-29T10:04:39.645939Z"
    },
    "papermill": {
     "duration": 0.023788,
     "end_time": "2025-03-29T10:04:39.647889",
     "exception": false,
     "start_time": "2025-03-29T10:04:39.624101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(all_labels, all_pred_probs):\n",
    "    '''\n",
    "    Args:\n",
    "        all_labels: true labels (len(val_dataset), n_labels)\n",
    "        all_pred_probs: probability of each class for each labels Tuple<(len(val_dataset), n_classes), \n",
    "                                                                        (len(val_dataset), n_classes) \n",
    "                                                                        (len(val_dataset), n_classes)>\n",
    "    '''\n",
    "\n",
    "    global val_dataset\n",
    "    global num_artist_classes, num_genre_classes, num_style_classes\n",
    "    all_labels = all_labels.cpu().numpy()\n",
    "    all_pred_labels = [all_pred_probs[i].argmax(axis=1) for i in range(3)]\n",
    "    \n",
    "    # TP[i][j] = true positive of class j in category (0: artist, 1: genre, 2: style)\n",
    "    TP = [[0] * 28 for _ in range(3)]\n",
    "    FP = [[0] * 28 for _ in range(3)]\n",
    "    TN = [[0] * 28 for _ in range(3)]\n",
    "    FN = [[0] * 28 for _ in range(3)]\n",
    "    for i in range(3): # artist, genre, style\n",
    "        for cls in range(val_dataset.get_num_classes()[i]): # class [0..n_classes]\n",
    "            for idx in range(len(all_labels)):\n",
    "                if all_labels[idx][i] == cls: \n",
    "                    if all_pred_labels[i][idx] == cls:\n",
    "                        TP[i][cls] += 1\n",
    "                    else:\n",
    "                        FN[i][cls] += 1 \n",
    "                else: \n",
    "                    if all_pred_labels[i][idx] == cls:\n",
    "                        FP[i][cls] += 1\n",
    "                    else:\n",
    "                        TN[i][cls] += 1 \n",
    "        \n",
    "    # P: Per class, O: Overall \n",
    "    metrics = {}\n",
    "    tp = 0.0\n",
    "    tp_fn = 0.0\n",
    "    tp_fp = 0.0\n",
    "    # Artist\n",
    "    for cls in range(num_artist_classes):\n",
    "        cls_name = val_dataset.get_label_artist(cls)\n",
    "        metrics[f'PP_{cls_name}'] = TP[0][cls] / max(1, TP[0][cls] + FN[0][cls])\n",
    "        metrics[f'PR_{cls_name}'] = TP[0][cls] / max(1, TP[0][cls] + FP[0][cls])\n",
    "        metrics[f'PF1_{cls_name}'] = 2 * (metrics[f'PP_{cls_name}'] * metrics[f'PR_{cls_name}']) / max(1, (metrics[f'PP_{cls_name}'] + metrics[f'PR_{cls_name}']))\n",
    "        tp = tp + TP[0][cls]\n",
    "        tp_fn = tp_fn + max(1e-5, TP[0][cls] + FN[0][cls])\n",
    "        tp_fp = tp_fp + max(1e-5, TP[0][cls] + FP[0][cls])\n",
    "    \n",
    "    # Genre\n",
    "    for cls in range(num_genre_classes):\n",
    "        cls_name = val_dataset.get_label_genre(cls)\n",
    "        metrics[f'PP_{cls_name}'] = TP[1][cls] / max(1, TP[1][cls] + FN[1][cls])\n",
    "        metrics[f'PR_{cls_name}'] = TP[1][cls] / max(1, TP[1][cls] + FP[1][cls])\n",
    "        metrics[f'PF1_{cls_name}'] = 2 * (metrics[f'PP_{cls_name}'] * metrics[f'PR_{cls_name}']) / max(1, (metrics[f'PP_{cls_name}'] + metrics[f'PR_{cls_name}']))\n",
    "        tp = tp + TP[1][cls]\n",
    "        tp_fn = tp_fn + max(1e-5, TP[1][cls] + FN[1][cls])\n",
    "        tp_fp = tp_fp + max(1e-5, TP[1][cls] + FP[1][cls])\n",
    "    \n",
    "    # Style\n",
    "    for cls in range(num_style_classes):\n",
    "        cls_name = val_dataset.get_label_style(cls)\n",
    "        metrics[f'PP_{cls_name}'] = TP[2][cls] / max(1, TP[2][cls] + FN[2][cls])\n",
    "        metrics[f'PR_{cls_name}'] = TP[2][cls] / max(1, TP[2][cls] + FP[2][cls])\n",
    "        metrics[f'PF1_{cls_name}'] = 2 * (metrics[f'PP_{cls_name}'] * metrics[f'PR_{cls_name}']) / max(1, (metrics[f'PP_{cls_name}'] + metrics[f'PR_{cls_name}']))\n",
    "        tp = tp + TP[2][cls]\n",
    "        tp_fn = tp_fn + max(1e-5, TP[2][cls] + FN[2][cls])\n",
    "        tp_fp = tp_fp + max(1e-5, TP[2][cls] + FP[2][cls])\n",
    "    \n",
    "    metrics[f'OP'] = tp / tp_fn\n",
    "    metrics[f'OR'] = tp / tp_fp\n",
    "    metrics[f'OF1'] = 2 * (metrics[f'OP'] * metrics[f'OR']) / (metrics[f'OP'] + metrics[f'OR'])\n",
    "    return metrics\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    all_labels = []\n",
    "    all_pred_probs_artist, all_pred_probs_genre, all_pred_probs_style = [], [], []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(val_dataset), desc=f'Validating', unit='img') as pbar:\n",
    "            for batch in dataloader:\n",
    "                images, labels = batch['images'], batch['labels']\n",
    "                images = images.to(device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                labels = labels.to(device, dtype=torch.long) # (batch_size, 3)\n",
    "                \n",
    "                logits_pred = model(images, labels) # (batch_size, 3)\n",
    "                loss_artist = criterion(logits_pred[0], labels[:, 0])\n",
    "                loss_genre = criterion(logits_pred[1], labels[:, 1])\n",
    "                loss_style = criterion(logits_pred[2], labels[:, 2])\n",
    "                loss = loss_artist + loss_genre + loss_style\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                all_pred_probs_artist.append(torch.softmax(logits_pred[0], dim=1))\n",
    "                all_pred_probs_genre.append(torch.softmax(logits_pred[1], dim=1))\n",
    "                all_pred_probs_style.append(torch.softmax(logits_pred[2], dim=1))\n",
    "                all_labels.append(labels)\n",
    "                pbar.update(images.shape[0])\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    all_pred_probs_artist = torch.cat(all_pred_probs_artist)\n",
    "    all_pred_probs_genre = torch.cat(all_pred_probs_genre)\n",
    "    all_pred_probs_style = torch.cat(all_pred_probs_style)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    metrics = {}\n",
    "    metrics = calculate_metrics(all_labels, (all_pred_probs_artist, all_pred_probs_genre, all_pred_probs_style))\n",
    "    metrics['loss'] = avg_loss\n",
    "\n",
    "    # Artist\n",
    "    print(\" \\n================================ Artist ================================\")\n",
    "    for cls in range(num_artist_classes):\n",
    "        cls_name = val_dataset.get_label_artist(cls)\n",
    "        print(f\"{cls_name} (Precision, Recall, F1 score): ({ metrics[f'PP_{cls_name}'] }, { metrics[f'PR_{cls_name}'] }, { metrics[f'PF1_{cls_name}'] })\")\n",
    "    \n",
    "    # Genre\n",
    "    print(\" \\n================================ Genre ================================\")\n",
    "    for cls in range(num_genre_classes):\n",
    "        cls_name = val_dataset.get_label_genre(cls)\n",
    "        print(f\"{cls_name} (Precision, Recall, F1 score): ({ metrics[f'PP_{cls_name}'] }, { metrics[f'PR_{cls_name}'] }, { metrics[f'PF1_{cls_name}'] })\")\n",
    "    \n",
    "    # Style\n",
    "    print(\" \\n================================ Style ================================\")\n",
    "    for cls in range(num_style_classes):\n",
    "        cls_name = val_dataset.get_label_style(cls)\n",
    "        print(f\"{cls_name} (Precision, Recall, F1 score): ({ metrics[f'PP_{cls_name}'] }, { metrics[f'PR_{cls_name}'] }, { metrics[f'PF1_{cls_name}'] })\")\n",
    "    \n",
    "    print(\" \\n================================ Overall ================================\")\n",
    "    print(f\"Overall Precision: {metrics['OP']}\")\n",
    "    print(f\"Overall Recall: {metrics['OR']}\")\n",
    "    print(f\"Overall F1: {metrics['OF1']}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdf2c99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:39.656780Z",
     "iopub.status.busy": "2025-03-29T10:04:39.656493Z",
     "iopub.status.idle": "2025-03-29T10:04:39.952419Z",
     "shell.execute_reply": "2025-03-29T10:04:39.951521Z"
    },
    "papermill": {
     "duration": 0.302125,
     "end_time": "2025-03-29T10:04:39.954012",
     "exception": false,
     "start_time": "2025-03-29T10:04:39.651887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 4\n",
    "learning_rate = 5e-4\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.000025)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.66)\n",
    "\n",
    "global_step = 0\n",
    "n_train = len(train_dataset)\n",
    "threshold = 0.7\n",
    "\n",
    "# Per epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1 = []\n",
    "\n",
    "# Per step\n",
    "train_losses_steps = []\n",
    "\n",
    "model.to(device)\n",
    "best_model = model\n",
    "best_val_f1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d823433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:39.962772Z",
     "iopub.status.busy": "2025-03-29T10:04:39.962507Z",
     "iopub.status.idle": "2025-03-29T10:04:42.696792Z",
     "shell.execute_reply": "2025-03-29T10:04:42.696027Z"
    },
    "papermill": {
     "duration": 2.74011,
     "end_time": "2025-03-29T10:04:42.698258",
     "exception": false,
     "start_time": "2025-03-29T10:04:39.958148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-161c90b2b2a1>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model_path = '/kaggle/input/wikiart_general_epoch2/pytorch/default/1/wikiart_general_CNN_RNN_epoch2.pt'\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict['model_state_dict'])\n",
    "optimizer.load_state_dict(state_dict['optim_state_dict'])\n",
    "scheduler.load_state_dict(state_dict['scheduler_state_dict'])\n",
    "global_step = state_dict['global_step']\n",
    "last_epoch = state_dict['current_epochs']\n",
    "n_epochs = state_dict['n_epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d4df2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T10:04:42.707387Z",
     "iopub.status.busy": "2025-03-29T10:04:42.707168Z",
     "iopub.status.idle": "2025-03-29T12:16:57.830008Z",
     "shell.execute_reply": "2025-03-29T12:16:57.829073Z"
    },
    "papermill": {
     "duration": 7935.329044,
     "end_time": "2025-03-29T12:16:58.031615",
     "exception": false,
     "start_time": "2025-03-29T10:04:42.702571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4:  13%|█▎        | 7488/57338 [07:54<51:35, 16.10img/s, loss (batch)=3.26]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (99962094 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Epoch 3/4:  74%|███████▍  | 42368/57338 [43:46<15:39, 15.93img/s, loss (batch)=3.61]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "Epoch 3/4: 100%|██████████| 57338/57338 [59:09<00:00, 16.16img/s, loss (batch)=3.32]\n",
      "Validating: 100%|██████████| 24673/24673 [11:37<00:00, 35.38img/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "================================ Artist ================================\n",
      "Albrecht_Durer (Precision, Recall, F1 score): (0.46774193548387094, 0.8345323741007195, 0.599483204134367)\n",
      "Boris_Kustodiev (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Camille_Pissarro (Precision, Recall, F1 score): (0.12406015037593984, 0.868421052631579, 0.21547289275821133)\n",
      "Childe_Hassam (Precision, Recall, F1 score): (0.04242424242424243, 0.5384615384615384, 0.04568764568764569)\n",
      "Claude_Monet (Precision, Recall, F1 score): (0.4225, 0.4970588235294118, 0.42001470588235296)\n",
      "Edgar_Degas (Precision, Recall, F1 score): (0.2786885245901639, 0.7183098591549296, 0.40036942969291156)\n",
      "Eugene_Boudin (Precision, Recall, F1 score): (0.6024096385542169, 0.6896551724137931, 0.6430868167202574)\n",
      "Gustave_Dore (Precision, Recall, F1 score): (0.92, 0.8697478991596639, 0.8941684665226783)\n",
      "Ilya_Repin (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Ivan_Aivazovsky (Precision, Recall, F1 score): (0.5780346820809249, 0.8695652173913043, 0.6944444444444444)\n",
      "Ivan_Shishkin (Precision, Recall, F1 score): (0.6217948717948718, 0.6381578947368421, 0.6298701298701299)\n",
      "John_Singer_Sargent (Precision, Recall, F1 score): (0.02127659574468085, 0.8333333333333334, 0.03546099290780142)\n",
      "Marc_Chagall (Precision, Recall, F1 score): (0.5458515283842795, 0.7062146892655368, 0.6157635467980296)\n",
      "Martiros_Saryan (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Nicholas_Roerich (Precision, Recall, F1 score): (0.5431192660550459, 0.8176795580110497, 0.6527012127894156)\n",
      "Pablo_Picasso (Precision, Recall, F1 score): (0.017543859649122806, 0.6666666666666666, 0.023391812865497075)\n",
      "Paul_Cezanne (Precision, Recall, F1 score): (0.26011560693641617, 0.5172413793103449, 0.2690851106238788)\n",
      "Pierre_Auguste_Renoir (Precision, Recall, F1 score): (0.7666666666666667, 0.7892156862745098, 0.7777777777777779)\n",
      "Pyotr_Konchalovsky (Precision, Recall, F1 score): (0.3090909090909091, 0.6640625, 0.41051136363636365)\n",
      "Raphael_Kirchner (Precision, Recall, F1 score): (0.4090909090909091, 0.7974683544303798, 0.5407725321888412)\n",
      "Rembrandt (Precision, Recall, F1 score): (0.296137339055794, 0.7666666666666667, 0.4272445820433437)\n",
      "Salvador_Dali (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Vincent_van_Gogh (Precision, Recall, F1 score): (0.6084656084656085, 0.7549234135667396, 0.673828125)\n",
      "unknown artist (Precision, Recall, F1 score): (0.9674170928454684, 0.8486263990380168, 0.904136588730937)\n",
      " \n",
      "================================ Genre ================================\n",
      "abstract_painting (Precision, Recall, F1 score): (0.8013422818791947, 0.6791808873720137, 0.7352216748768472)\n",
      "cityscape (Precision, Recall, F1 score): (0.5391304347826087, 0.6757493188010899, 0.599758162031439)\n",
      "genre_painting (Precision, Recall, F1 score): (0.5363831747006448, 0.4795498215756245, 0.5063768115942029)\n",
      "illustration (Precision, Recall, F1 score): (0.3631578947368421, 0.5123762376237624, 0.372146951537259)\n",
      "landscape (Precision, Recall, F1 score): (0.8268030945844772, 0.6754332313965341, 0.743491921005386)\n",
      "nude_painting (Precision, Recall, F1 score): (0.3125, 0.5521472392638037, 0.3450920245398773)\n",
      "portrait (Precision, Recall, F1 score): (0.7484053862508859, 0.6606882168925965, 0.7018165706690297)\n",
      "religious_painting (Precision, Recall, F1 score): (0.5512493625701173, 0.6575425790754258, 0.5997226074895977)\n",
      "sketch_and_study (Precision, Recall, F1 score): (0.5583756345177665, 0.5699481865284974, 0.5641025641025641)\n",
      "still_life (Precision, Recall, F1 score): (0.5586124401913876, 0.5405092592592593, 0.5494117647058824)\n",
      "unknown genre (Precision, Recall, F1 score): (0.37463810075275045, 0.476319018404908, 0.3568945048152582)\n",
      " \n",
      "================================ Style ================================\n",
      "Abstract_Expressionism (Precision, Recall, F1 score): (0.5695443645083933, 0.5379388448471121, 0.553290623179965)\n",
      "Action_painting (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Analytical_Cubism (Precision, Recall, F1 score): (0.42424242424242425, 0.5833333333333334, 0.4912280701754386)\n",
      "Art_Nouveau (Precision, Recall, F1 score): (0.4546153846153846, 0.5699132111861138, 0.5057766367137355)\n",
      "Baroque (Precision, Recall, F1 score): (0.5872641509433962, 0.4348079161816065, 0.4996655518394648)\n",
      "Color_Field_Painting (Precision, Recall, F1 score): (0.6776859504132231, 0.6456692913385826, 0.6612903225806451)\n",
      "Contemporary_Realism (Precision, Recall, F1 score): (0.020833333333333332, 0.42857142857142855, 0.017857142857142856)\n",
      "Cubism (Precision, Recall, F1 score): (0.5417910447761194, 0.5353982300884956, 0.5385756676557863)\n",
      "Early_Renaissance (Precision, Recall, F1 score): (0.3645083932853717, 0.5409252669039146, 0.39434359985321354)\n",
      "Expressionism (Precision, Recall, F1 score): (0.4094059405940594, 0.4049951028403526, 0.33161480202868476)\n",
      "Fauvism (Precision, Recall, F1 score): (0.14642857142857144, 0.4019607843137255, 0.1177170868347339)\n",
      "High_Renaissance (Precision, Recall, F1 score): (0.16169154228855723, 0.37790697674418605, 0.12220872382274674)\n",
      "Impressionism (Precision, Recall, F1 score): (0.7279224093925473, 0.5955314261850073, 0.6551050878603423)\n",
      "Mannerism_Late_Renaissance (Precision, Recall, F1 score): (0.0731070496083551, 0.3373493975903614, 0.04932523828997452)\n",
      "Minimalism (Precision, Recall, F1 score): (0.6184538653366584, 0.6169154228855721, 0.6176836861768369)\n",
      "Naive_Art_Primitivism (Precision, Recall, F1 score): (0.4077669902912621, 0.4859504132231405, 0.3963090748615903)\n",
      "New_Realism (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Northern_Renaissance (Precision, Recall, F1 score): (0.5254901960784314, 0.5432432432432432, 0.53421926910299)\n",
      "Pointillism (Precision, Recall, F1 score): (0.4117647058823529, 0.7590361445783133, 0.5338983050847457)\n",
      "Pop_Art (Precision, Recall, F1 score): (0.5022522522522522, 0.5079726651480638, 0.5050962627406569)\n",
      "Post_Impressionism (Precision, Recall, F1 score): (0.46229338842975204, 0.3983088562527815, 0.36827110159735477)\n",
      "Realism (Precision, Recall, F1 score): (0.6259707983845915, 0.4757969303423849, 0.5406493158035954)\n",
      "Rococo (Precision, Recall, F1 score): (0.44089456869009586, 0.4808362369337979, 0.42399617058699113)\n",
      "Romanticism (Precision, Recall, F1 score): (0.4399049881235154, 0.4962486602357985, 0.43660452197467875)\n",
      "Symbolism (Precision, Recall, F1 score): (0.3284241531664212, 0.5631313131313131, 0.3698918492732926)\n",
      "Synthetic_Cubism (Precision, Recall, F1 score): (0.109375, 0.875, 0.19140625)\n",
      "Ukiyo_e (Precision, Recall, F1 score): (0.8057142857142857, 0.7877094972067039, 0.7966101694915254)\n",
      "unknown style (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      " \n",
      "================================ Overall ================================\n",
      "Overall Precision: 0.6464961699023224\n",
      "Overall Recall: 0.6464961692909288\n",
      "Overall F1: 0.6464961695966256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 57338/57338 [50:38<00:00, 18.87img/s, loss (batch)=3.09]\n",
      "Validating: 100%|██████████| 24673/24673 [09:23<00:00, 43.78img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "================================ Artist ================================\n",
      "Albrecht_Durer (Precision, Recall, F1 score): (0.657258064516129, 0.5970695970695971, 0.6257197696737044)\n",
      "Boris_Kustodiev (Precision, Recall, F1 score): (0.021164021164021163, 1.0, 0.04145077720207253)\n",
      "Camille_Pissarro (Precision, Recall, F1 score): (0.33458646616541354, 0.717741935483871, 0.4564102564102564)\n",
      "Childe_Hassam (Precision, Recall, F1 score): (0.13333333333333333, 0.55, 0.14666666666666667)\n",
      "Claude_Monet (Precision, Recall, F1 score): (0.42, 0.6339622641509434, 0.5052631578947369)\n",
      "Edgar_Degas (Precision, Recall, F1 score): (0.30601092896174864, 0.7887323943661971, 0.4409448818897638)\n",
      "Eugene_Boudin (Precision, Recall, F1 score): (0.5903614457831325, 0.8305084745762712, 0.6901408450704225)\n",
      "Gustave_Dore (Precision, Recall, F1 score): (0.9333333333333333, 0.8641975308641975, 0.8974358974358974)\n",
      "Ilya_Repin (Precision, Recall, F1 score): (0.031055900621118012, 0.5555555555555556, 0.03450655624568668)\n",
      "Ivan_Aivazovsky (Precision, Recall, F1 score): (0.7630057803468208, 0.7252747252747253, 0.7436619718309858)\n",
      "Ivan_Shishkin (Precision, Recall, F1 score): (0.5961538461538461, 0.6888888888888889, 0.6391752577319588)\n",
      "John_Singer_Sargent (Precision, Recall, F1 score): (0.05531914893617021, 0.5652173913043478, 0.06253469010175762)\n",
      "Marc_Chagall (Precision, Recall, F1 score): (0.4497816593886463, 0.8373983739837398, 0.5852272727272727)\n",
      "Martiros_Saryan (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Nicholas_Roerich (Precision, Recall, F1 score): (0.6275229357798165, 0.7651006711409396, 0.689516129032258)\n",
      "Pablo_Picasso (Precision, Recall, F1 score): (0.017543859649122806, 0.4444444444444444, 0.015594541910331383)\n",
      "Paul_Cezanne (Precision, Recall, F1 score): (0.26011560693641617, 0.703125, 0.3657875722543352)\n",
      "Pierre_Auguste_Renoir (Precision, Recall, F1 score): (0.7428571428571429, 0.8167539267015707, 0.7780548628428927)\n",
      "Pyotr_Konchalovsky (Precision, Recall, F1 score): (0.4254545454545455, 0.7748344370860927, 0.5492957746478873)\n",
      "Raphael_Kirchner (Precision, Recall, F1 score): (0.7142857142857143, 0.6875, 0.7006369426751592)\n",
      "Rembrandt (Precision, Recall, F1 score): (0.34334763948497854, 0.8695652173913043, 0.4923076923076923)\n",
      "Salvador_Dali (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Vincent_van_Gogh (Precision, Recall, F1 score): (0.6596119929453262, 0.7601626016260162, 0.7063267233238905)\n",
      "unknown artist (Precision, Recall, F1 score): (0.9628829018822165, 0.858788676761027, 0.9078617055650834)\n",
      " \n",
      "================================ Genre ================================\n",
      "abstract_painting (Precision, Recall, F1 score): (0.7751677852348994, 0.7319391634980988, 0.7529335071707954)\n",
      "cityscape (Precision, Recall, F1 score): (0.605072463768116, 0.6549019607843137, 0.6290018832391713)\n",
      "genre_painting (Precision, Recall, F1 score): (0.4528707399447344, 0.55765595463138, 0.499830565909861)\n",
      "illustration (Precision, Recall, F1 score): (0.38596491228070173, 0.5744125326370757, 0.4434061655444093)\n",
      "landscape (Precision, Recall, F1 score): (0.80559021712004, 0.7189309576837416, 0.7597975756149228)\n",
      "nude_painting (Precision, Recall, F1 score): (0.3385416666666667, 0.5891238670694864, 0.39888595166163143)\n",
      "portrait (Precision, Recall, F1 score): (0.7623434916135129, 0.6415506958250498, 0.6967505127928317)\n",
      "religious_painting (Precision, Recall, F1 score): (0.6884242733299337, 0.5653266331658291, 0.6208323752586801)\n",
      "sketch_and_study (Precision, Recall, F1 score): (0.6252115059221658, 0.5390226112326769, 0.5789267528397963)\n",
      "still_life (Precision, Recall, F1 score): (0.5406698564593302, 0.6243093922651933, 0.5794871794871795)\n",
      "unknown genre (Precision, Recall, F1 score): (0.41053850607990733, 0.4771197846567968, 0.3917520872283369)\n",
      " \n",
      "================================ Style ================================\n",
      "Abstract_Expressionism (Precision, Recall, F1 score): (0.6258992805755396, 0.5278058645096056, 0.5726823916620954)\n",
      "Action_painting (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Analytical_Cubism (Precision, Recall, F1 score): (0.6060606060606061, 0.5263157894736842, 0.5633802816901409)\n",
      "Art_Nouveau (Precision, Recall, F1 score): (0.4807692307692308, 0.5458515283842795, 0.5112474437627812)\n",
      "Baroque (Precision, Recall, F1 score): (0.6139937106918238, 0.49713558243157224, 0.5494196271544144)\n",
      "Color_Field_Painting (Precision, Recall, F1 score): (0.6528925619834711, 0.7365967365967366, 0.692223439211391)\n",
      "Contemporary_Realism (Precision, Recall, F1 score): (0.06944444444444445, 0.5555555555555556, 0.0771604938271605)\n",
      "Cubism (Precision, Recall, F1 score): (0.5611940298507463, 0.5521292217327459, 0.5566247224278312)\n",
      "Early_Renaissance (Precision, Recall, F1 score): (0.6019184652278178, 0.42759795570698467, 0.5)\n",
      "Expressionism (Precision, Recall, F1 score): (0.3797029702970297, 0.5032808398950132, 0.3821944596034407)\n",
      "Fauvism (Precision, Recall, F1 score): (0.16428571428571428, 0.40707964601769914, 0.13375474083438685)\n",
      "High_Renaissance (Precision, Recall, F1 score): (0.26616915422885573, 0.28232189973614774, 0.15029076254610851)\n",
      "Impressionism (Precision, Recall, F1 score): (0.6888718734047984, 0.6558930741190766, 0.6719780903771941)\n",
      "Mannerism_Late_Renaissance (Precision, Recall, F1 score): (0.21148825065274152, 0.3875598086124402, 0.16392869189351258)\n",
      "Minimalism (Precision, Recall, F1 score): (0.7356608478802993, 0.6133056133056133, 0.6689342403628119)\n",
      "Naive_Art_Primitivism (Precision, Recall, F1 score): (0.39944521497919555, 0.5806451612903226, 0.4638718625564852)\n",
      "New_Realism (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      "Northern_Renaissance (Precision, Recall, F1 score): (0.6967320261437908, 0.4532312925170068, 0.5492014425553838)\n",
      "Pointillism (Precision, Recall, F1 score): (0.6339869281045751, 0.6643835616438356, 0.6488294314381271)\n",
      "Pop_Art (Precision, Recall, F1 score): (0.4617117117117117, 0.5163727959697733, 0.47683073501713297)\n",
      "Post_Impressionism (Precision, Recall, F1 score): (0.40960743801652894, 0.4602437608821822, 0.37703853551608524)\n",
      "Realism (Precision, Recall, F1 score): (0.6123019571295434, 0.5022935779816514, 0.5518689626207476)\n",
      "Rococo (Precision, Recall, F1 score): (0.45686900958466453, 0.48067226890756304, 0.43920852686122375)\n",
      "Romanticism (Precision, Recall, F1 score): (0.49596199524940615, 0.4899108399812295, 0.4859543153828062)\n",
      "Symbolism (Precision, Recall, F1 score): (0.44329896907216493, 0.441025641025641, 0.39101242400211467)\n",
      "Synthetic_Cubism (Precision, Recall, F1 score): (0.328125, 0.5121951219512195, 0.3361280487804878)\n",
      "Ukiyo_e (Precision, Recall, F1 score): (0.8514285714285714, 0.7468671679197995, 0.7957276368491323)\n",
      "unknown style (Precision, Recall, F1 score): (0.0, 0.0, 0.0)\n",
      " \n",
      "================================ Overall ================================\n",
      "Overall Precision: 0.6598305840392331\n",
      "Overall Recall: 0.6598305836826596\n",
      "Overall F1: 0.6598305838609463\n"
     ]
    }
   ],
   "source": [
    "n_epochs = n_epochs + 2\n",
    "for epoch in range(last_epoch+1, n_epochs+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    with tqdm(total=n_train, desc=f'Epoch {epoch}/{n_epochs}', unit='img') as pbar:\n",
    "        for batch in train_dataloader:\n",
    "            images, labels = batch['images'], batch['labels']\n",
    "            images = images.to(device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            labels = labels.to(device, dtype=torch.long) # (batch_size, 3)\n",
    "\n",
    "            logits_pred = model(images, labels) # (3, batch_size)\n",
    "            loss_artist = criterion(logits_pred[0], labels[:, 0]) # (batch_size, 24), (batch_size)\n",
    "            loss_genre = criterion(logits_pred[1], labels[:, 1]) # (batch_size, 11), (batch_size)\n",
    "            loss_style = criterion(logits_pred[2], labels[:, 2]) # (batch_size, 28), (batch_size)\n",
    "            loss = loss_artist + loss_genre + loss_style\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            train_losses_steps.append(loss.item() / batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_step += 1\n",
    "            pbar.update(images.shape[0])\n",
    "            pbar.set_postfix(**{f'loss (batch)': loss.item()})\n",
    "\n",
    "    train_losses.append(epoch_loss / len(train_dataloader))\n",
    "    val_metrics = evaluate(model, val_dataloader, criterion, device)\n",
    "    scheduler.step(val_metrics['loss'])\n",
    "    val_losses.append(val_metrics['loss'])\n",
    "    val_f1.append(val_metrics['OF1'])\n",
    "    if val_f1[-1] > best_val_f1:\n",
    "        best_model = model\n",
    "        best_val_f1 = val_f1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d610499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T12:16:58.820105Z",
     "iopub.status.busy": "2025-03-29T12:16:58.819824Z",
     "iopub.status.idle": "2025-03-29T12:16:59.354334Z",
     "shell.execute_reply": "2025-03-29T12:16:59.353659Z"
    },
    "papermill": {
     "duration": 0.733552,
     "end_time": "2025-03-29T12:16:59.355930",
     "exception": false,
     "start_time": "2025-03-29T12:16:58.622378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = best_model\n",
    "state_dict = {\n",
    "    'lr': learning_rate,\n",
    "    'global_step': global_step,\n",
    "    'current_epochs': epoch,\n",
    "    'n_epochs': n_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optim_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(state_dict, str('/kaggle/working/wikiart_general_CNN_RNN_epoch{}.pt'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd4ac4f",
   "metadata": {
    "papermill": {
     "duration": 0.197323,
     "end_time": "2025-03-29T12:16:59.820280",
     "exception": false,
     "start_time": "2025-03-29T12:16:59.622957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Find outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d59d8",
   "metadata": {
    "papermill": {
     "duration": 0.19627,
     "end_time": "2025-03-29T12:17:00.212922",
     "exception": false,
     "start_time": "2025-03-29T12:17:00.016652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Idea: Extract features -> UMAP -> Plot"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6911215,
     "isSourceIdPinned": true,
     "sourceId": 11088051,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 282416,
     "modelInstanceId": 261263,
     "sourceId": 306259,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7958.446318,
   "end_time": "2025-03-29T12:17:02.272851",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-29T10:04:23.826533",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
